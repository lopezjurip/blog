+++
categories = ["recsys"]
date = "2016-08-21T23:36:39-03:00"
description = ""
keywords = []
title = "Comentarios sobre Item-Based CF"

+++

El paper aborda el tema de la **escalabilidad** y **esparcicidad** de los _Filtros Colaborativos_. En particular el cuello de botella ocurre al buscar los vecinos m√°s cercanos de los usuarios, que se complica m√°s cuando empiezan a aparecer m√°s personas. As√≠ tambi√©n el problema de la precisi√≥n cuando tienen muchos √≠tems pero pocos _ratings_.

El _CF_ basado en √≠tems parte haciendo algo similar a los esquemas basados en modelos. Esto es, calcular las similaridades entre los √≠tems y luego escoger los √≠tems m√°s similares.

Para medir la similaridad proponen tres m√©todos: _Cosine-based_, _Correlation-based_ y _Adjusted-Cosine_. De los cuales el √∫ltimo tiene mejor rendimiento (menor _MAE_). La gracia de este √∫ltimo es que regula la parcialidad de los _ratings_ del usuario (ya sea _pesimista_, _optimista_, _bi-modal_, etc), versus el _Correlation-based_ que regula los _ratings_ del √≠tem en particular.

El gran aporte del paper es mostrar que **es posible obtener muy buen rendimiento eligiendo pocos √≠tems similares**.

Sin embargo, esto parece no aplicar cuando se trata de ambientes de gran interacci√≥n y generaci√≥n de contenido. Pues espera que el _set_ de √≠tems sea relativamente est√°tico. Por ejemplo, esto no servir√≠a para recomendar _Tweets_ o, en un caso algo rid√≠culo, acciones en la bolsa.

Tampoco queda claro si esto funcionar√≠a para √≠tems nuevos (_cold-start_). **Quiz√°s se podr√≠an aplicar medidas de similaridad en base a su contenido para soportar este tipo de casos**, ya que son √≠tems. Podemos incluir, por ejemplo, similaridad de g√©nero musical en el caso de canciones o de precio y marca en un _e-commerce_. Una ventaja de esto versus una metodolog√≠a _user-based_ es que no tenemos que hacerle preguntas al usuario para poder encontrar similitudes üòÑ.
